{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training Deep Neural-Network with Pytorch for Digit Recognition "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this notebook we are going to learn how to build deep Neural-Network using Pytorch. We will be using MNIST data set to train a deep neural-net that can classify hand-written digits from images. More specifically our learning goal for this tutorial will be as following,\n",
    "\n",
    "1. How to load an existing data set in Pytorch\n",
    "2. How to use *torch.nn.sequential* to build a deep neural network\n",
    "3. How to setup data for forward pass through the neural-net\n",
    "\n",
    "Each of the above steps will be impllemented in different cells."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary packages\n",
    "%matplotlib inline\n",
    "%config InlineBackend.figure_format = 'retina'\n",
    "import numpy as np\n",
    "import torch\n",
    "import helper\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn, optim\n",
    "import torch.nn.functional as F\n",
    "from torchvision import datasets, transforms\n",
    "\n",
    "# Define a transform to normalize the data\n",
    "transform = transforms.Compose([transforms.ToTensor(),\n",
    "                                transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5)),\n",
    "                              ])\n",
    "# Download and load the training data\n",
    "trainset = datasets.MNIST('~/.pytorch/MNIST_data/', download=True, train=True, transform=transform)\n",
    "trainloader = torch.utils.data.DataLoader(trainset, batch_size=64, shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### We will build the following neural network\n",
    "\n",
    "<img src=\"figures/mlp_mnist.png\" width=600px>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Start building the network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Hyperparameters for our network\n",
    "# input_size = 784\n",
    "# hidden_sizes = [128, 64]\n",
    "# output_size = 10\n",
    "\n",
    "# # Build a feed-forward network\n",
    "# model = torch.nn.Sequential(torch.nn.Linear(input_size, hidden_sizes[0]),\n",
    "#                       torch.nn.ReLU(),\n",
    "#                       torch.nn.Linear(hidden_sizes[0], hidden_sizes[1]),\n",
    "#                       torch.nn.ReLU(),\n",
    "#                       torch.nn.Linear(hidden_sizes[1], output_size),\n",
    "#                       torch.nn.Softmax(dim=1))\n",
    "# print(model)\n",
    "\n",
    "# # Define the loss\n",
    "# # criterion = torch.nn.CrossEntropyLoss()\n",
    "# criterion = torch.nn.NLLLoss()\n",
    "\n",
    "# # Optimizers require the parameters to optimize and a learning rate\n",
    "# optimizer = torch.optim.SGD(model.parameters(), lr=0.003)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "output with shape [1, 28, 28] doesn't match the broadcast shape [3, 28, 28]",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-4-283a0143c3f0>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;31m# Get our data\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m \u001b[0mimages\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrainloader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     14\u001b[0m \u001b[0;31m# Flatten images\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0mimages\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mimages\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mview\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimages\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    558\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnum_workers\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# same-process loading\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    559\u001b[0m             \u001b[0mindices\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msample_iter\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 560\u001b[0;31m             \u001b[0mbatch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcollate_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mindices\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    561\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    562\u001b[0m                 \u001b[0mbatch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    558\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnum_workers\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# same-process loading\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    559\u001b[0m             \u001b[0mindices\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msample_iter\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 560\u001b[0;31m             \u001b[0mbatch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcollate_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mindices\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    561\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    562\u001b[0m                 \u001b[0mbatch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/torchvision/datasets/mnist.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, index)\u001b[0m\n\u001b[1;32m     93\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     94\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 95\u001b[0;31m             \u001b[0mimg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     96\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     97\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtarget_transform\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/torchvision/transforms/transforms.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, img)\u001b[0m\n\u001b[1;32m     59\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     60\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mt\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransforms\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 61\u001b[0;31m             \u001b[0mimg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     62\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mimg\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     63\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/torchvision/transforms/transforms.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, tensor)\u001b[0m\n\u001b[1;32m    162\u001b[0m             \u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mNormalized\u001b[0m \u001b[0mTensor\u001b[0m \u001b[0mimage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    163\u001b[0m         \"\"\"\n\u001b[0;32m--> 164\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnormalize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstd\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minplace\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    165\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    166\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__repr__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/torchvision/transforms/functional.py\u001b[0m in \u001b[0;36mnormalize\u001b[0;34m(tensor, mean, std, inplace)\u001b[0m\n\u001b[1;32m    206\u001b[0m     \u001b[0mmean\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat32\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    207\u001b[0m     \u001b[0mstd\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstd\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat32\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 208\u001b[0;31m     \u001b[0mtensor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msub_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdiv_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstd\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    209\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mtensor\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    210\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: output with shape [1, 28, 28] doesn't match the broadcast shape [3, 28, 28]"
     ]
    }
   ],
   "source": [
    "# Build a feed-forward network\n",
    "model = nn.Sequential(nn.Linear(784, 128),\n",
    "                      nn.ReLU(),\n",
    "                      nn.Linear(128, 64),\n",
    "                      nn.ReLU(),\n",
    "                      nn.Linear(64, 10),\n",
    "                      nn.LogSoftmax(dim=1))\n",
    "\n",
    "# Define the loss\n",
    "criterion = nn.NLLLoss()\n",
    "\n",
    "# Get our data\n",
    "images, labels = next(iter(trainloader))\n",
    "# Flatten images\n",
    "images = images.view(images.shape[0], -1)\n",
    "\n",
    "# Forward pass, get our log-probabilities\n",
    "logps = model(images)\n",
    "# Calculate the loss with the logps and the labels\n",
    "loss = criterion(logps, labels)\n",
    "\n",
    "print(loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Warmup with one batch of Data to perform a forward pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x648 with 2 Axes>"
      ]
     },
     "metadata": {
      "image/png": {
       "height": 226,
       "width": 423
      },
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Grab some data \n",
    "dataiter = iter(trainloader)\n",
    "images, labels = dataiter.next()\n",
    "\n",
    "# Resize images into a 1D vector, new shape is (batch size, color channels, image pixels) \n",
    "images.resize_(images.shape[0], 1, 784)\n",
    "# or images.resize_(images.shape[0], 1, 784) to automatically get batch size\n",
    "\n",
    "# Forward pass through the network\n",
    "img_idx = 0\n",
    "ps = model.forward(images[img_idx,:])\n",
    "\n",
    "img = images[img_idx]\n",
    "helper.view_classify(img.view(1, 28, 28), ps)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train the network with training dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-68-971184bc50da>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0me\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0mrunning_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m     \u001b[0;32mfor\u001b[0m \u001b[0mimages\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtrainloader\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m         \u001b[0;31m# Flatten MNIST images into a 784 long vector\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    558\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnum_workers\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# same-process loading\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    559\u001b[0m             \u001b[0mindices\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msample_iter\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 560\u001b[0;31m             \u001b[0mbatch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcollate_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mindices\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    561\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    562\u001b[0m                 \u001b[0mbatch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    558\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnum_workers\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# same-process loading\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    559\u001b[0m             \u001b[0mindices\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msample_iter\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 560\u001b[0;31m             \u001b[0mbatch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcollate_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mindices\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    561\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    562\u001b[0m                 \u001b[0mbatch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/torchvision/datasets/mnist.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, index)\u001b[0m\n\u001b[1;32m     86\u001b[0m             \u001b[0mtuple\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mimage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0mwhere\u001b[0m \u001b[0mtarget\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mindex\u001b[0m \u001b[0mof\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mtarget\u001b[0m \u001b[0;32mclass\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     87\u001b[0m         \"\"\"\n\u001b[0;32m---> 88\u001b[0;31m         \u001b[0mimg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtargets\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     89\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     90\u001b[0m         \u001b[0;31m# doing this so that it is consistent with all other datasets\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "epochs = 5\n",
    "for e in range(epochs):\n",
    "    running_loss = 0\n",
    "    for images, labels in trainloader:\n",
    "        \n",
    "        # Flatten MNIST images into a 784 long vector\n",
    "        images = images.view(images.shape[0], -1)\n",
    "    \n",
    "        # TODO: Training pass\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        output = model.forward(images)\n",
    "        loss = criterion(output, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    else:\n",
    "        print(f\"Training loss: {running_loss/len(trainloader)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Predict Digits\n",
    "Now that we have a trained network, we can now start predicting data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "images, labels = next(iter(trainloader))\n",
    "\n",
    "img = images[0].view(1, 784)\n",
    "# Turn off gradients to speed up this part\n",
    "with torch.no_grad():\n",
    "    logps = model.forward(img)\n",
    "\n",
    "# Output of the network are logits, need to take softmax for probabilities\n",
    "ps = torch.exp(logps)\n",
    "helper.view_classify(img.view(1, 28, 28), ps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
